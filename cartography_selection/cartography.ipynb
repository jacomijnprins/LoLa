{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model on cartography classes\n",
    "\n",
    "I want to see whether selecting easy-to-learn, hard-to-learn or ambiguous data instances will omprove performance on our 2k curriculum as well.\n",
    "Might make multiple curriculum with:\n",
    "- an equal mix of the three groups\n",
    "- just ambiguous \n",
    "- just hard-to-learn\n",
    "\n",
    "Paper: Swayamdipta, et all. (2020). Dataset cartography: Mapping and diagnosing datasets with training dynamics. arXiv preprint arXiv:2009.10795."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the datasets\n",
    "### Importing cartography data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('snli_roberta_0_6_data_map_coordinates.jsonl.txt', header=None)\n",
    "data.columns = [\"guid\", \"index\", \"confidence\", \"variability\", \"correctness\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549367\n",
      "                         guid         index               confidence  \\\n",
      "0       {\"guid\":4446013212032       index:0  confidence:0.6756780396   \n",
      "1        {\"guid\":568940932410       index:1  confidence:0.8437704568   \n",
      "2       {\"guid\":4107496324431       index:2  confidence:0.8646389991   \n",
      "3        {\"guid\":151853983012       index:3  confidence:0.8720001976   \n",
      "4       {\"guid\":6041167176312       index:4   confidence:0.653920905   \n",
      "...                       ...           ...                      ...   \n",
      "549362  {\"guid\":5732659631411  index:549362  confidence:0.9975628853   \n",
      "549363  {\"guid\":3920105265011  index:549363  confidence:0.9949818949   \n",
      "549364  {\"guid\":6888801884010  index:549364  confidence:0.9364117483   \n",
      "549365   {\"guid\":189022647122  index:549365  confidence:0.7770978212   \n",
      "549366  {\"guid\":4506417051031  index:549366  confidence:0.9137195448   \n",
      "\n",
      "                     variability     correctness  \n",
      "0        variability:0.301201277  correctness:4}  \n",
      "1       variability:0.3148066146  correctness:5}  \n",
      "2       variability:0.3021121707  correctness:5}  \n",
      "3       variability:0.1544543004  correctness:6}  \n",
      "4       variability:0.3424947134  correctness:4}  \n",
      "...                          ...             ...  \n",
      "549362  variability:0.0027843492  correctness:6}  \n",
      "549363  variability:0.0105341857  correctness:6}  \n",
      "549364  variability:0.0803700148  correctness:6}  \n",
      "549365  variability:0.0661821039  correctness:6}  \n",
      "549366  variability:0.0815413539  correctness:6}  \n",
      "\n",
      "[549367 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data) # 4804607632"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing SNLI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'assigntools'...\n"
     ]
    }
   ],
   "source": [
    "# if assigntools not yet downloaded run line\n",
    "# ! git clone https://github.com/kovvalsky/assigntools.git\n",
    "\n",
    "# if zip file of SNLI data not yet downloaded run lines\n",
    "# !wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
    "# !unzip snli_1.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assigntools.LoLa.read_nli import snli_jsonl2dict, sen2anno_from_nli_problems\n",
    "from assigntools.LoLa.sen_analysis import spacy_process_sen2tok, display_doc_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found .json files for ['dev', 'test', 'train'] parts\n",
      "processing DEV:\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:02, 4381.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9842 problems read\n",
      "0 problems have a wrong annotator label\n",
      "processing TEST:\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:01, 8566.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9824 problems read\n",
      "0 problems have a wrong annotator label\n",
      "processing TRAIN:\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "550152it [01:13, 7473.49it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549169 problems read\n",
      "198 problems have a wrong annotator label\n",
      "Most common weird labels: //(198)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this is Lasha's code for downloading SNLI\n",
    "SNLI, S2A = snli_jsonl2dict('snli_1.0') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               [neutral]\n",
      "1         [contradiction]\n",
      "2            [entailment]\n",
      "3               [neutral]\n",
      "4            [entailment]\n",
      "               ...       \n",
      "550147    [contradiction]\n",
      "550148          [neutral]\n",
      "550149          [neutral]\n",
      "550150    [contradiction]\n",
      "550151       [entailment]\n",
      "Name: annotator_labels, Length: 550152, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_snli = pd.read_json('snli_1.0_train.jsonl', lines=True)\n",
    "# data.columns = [\"guid\", \"index\", \"confidence\", \"variability\", \"correctness\"]\n",
    "# print(data_snli[\"annotator_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550152, 10)\n"
     ]
    }
   ],
   "source": [
    "print(data_snli.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have to find a way to match up the number of instances of the cartography data to the number of instances in the original SNLI dataset in order to match the ID's from the cartography values to the sentences to train the model on.\n",
    "- The cartography dataset has *549367*\n",
    "- The original SNLI dataset downloaded from Stanford or huggingface has *550152*\n",
    "- From Lasha's code has *549169* with 198 with wrong annotater labels\n",
    "\n",
    "This suggests that if we delete the instances with wrong annotated labels from the cartography dataset that the instances from the cartography dataset would match that of Lasha's processed dataset and we could match up the ID's of the two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the curiculi\n",
    "I want to use the different groups (hard-to-learn, easy-to-learn, ambiguous) based on the values in the cartography dataset. Then try the same training sets (just hard-to-learn and just ambiguous) as used in the paper and, if times allows, also a mix. This will allow us to answer the question can we find the same patterns as the paper in our curriculums of 2k? \n",
    "\n",
    "Tasks:\n",
    "- Look into what the values are that they used in the paper to destinguish the three groups. Paper doesn't mention values --> look at code\n",
    "- How to take 2k datapoints from those bins. Do you want to take those randomly or make smaller bins inside of the groups to select a good sample of that particular group?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
